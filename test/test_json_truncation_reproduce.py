#!/usr/bin/env python3
"""
å•ç‹¬æµ‹è¯•è„šæœ¬ï¼šå¤ç°JSONæˆªæ–­é—®é¢˜

æ­¤è„šæœ¬ç”¨äºå¤ç°ç‰¹å®šcommitå¯¼è‡´çš„JSONè§£æé”™è¯¯ï¼š
- Commit: e126b9c4ee254b4ecaf72b12603bd34ea5bc1644
- é—®é¢˜ï¼šGPTè¿”å›çš„JSONå“åº”è¢«æˆªæ–­ï¼Œå¯¼è‡´JSONè§£æå¤±è´¥
"""

import os
import sys
import json
import datetime
import toml
from dotenv import load_dotenv

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥æœ¬åœ°æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from logs import logger
from commit_fetch import CommitFetcher
from call_gpt import CallGPT

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(override=True)
PERSONAL_TOKEN = os.getenv("PERSONAL_TOKEN")

class JsonTruncationTester(CommitFetcher, CallGPT):
    """
    JSONæˆªæ–­é—®é¢˜å¤ç°æµ‹è¯•å™¨
    """
    
    def __init__(self):
        self.headers = {"Authorization": "token " + PERSONAL_TOKEN}
        self.topic_path = "articles/ai-foundry"  # è®¾ç½®ä¸»é¢˜è·¯å¾„è¿‡æ»¤
        self.max_input_token = 30000
        self.language = "Chinese"
        
        # åŠ è½½ç”Ÿäº§ç¯å¢ƒä½¿ç”¨çš„system prompts
        self.system_prompts = self.load_production_prompts()
    
    def load_production_prompts(self):
        """åŠ è½½ç”Ÿäº§ç¯å¢ƒä½¿ç”¨çš„system prompts"""
        try:
            # è·å–çˆ¶ç›®å½•ä¸­çš„prompts.tomlæ–‡ä»¶è·¯å¾„
            prompts_file = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'prompts.toml')
            with open(prompts_file, 'r') as f:  
                data = toml.load(f)
                
            # ç”Ÿäº§ç¯å¢ƒä½¿ç”¨çš„é»˜è®¤prompté…ç½®ï¼ˆæ¥è‡ªeyes_on_docs.pyï¼‰
            default_prompt = {
                "GPT_SUMMARY_PROMPT": "gpt_summary_prompt_v2",  
                "GPT_TITLE_PROMPT": "gpt_title_prompt_v4",  
                "GPT_SIMILARITY_PROMPT": "gpt_similarity_prompt_v1",  
                "GPT_WEEKLY_SUMMARY_PROMPT": "gpt_weekly_summary_prompt_v1",
                "GPT_STRUCTURED_PROMPT": "gpt_structured_prompt_v1"  # ç»“æ„åŒ–è¾“å‡ºprompt
            }
            
            # å°†prompté”®åæ˜ å°„åˆ°å®é™…çš„promptå†…å®¹
            system_prompt = {}
            for k, v in default_prompt.items():
                system_prompt[k] = data[v]['prompt']
            
            logger.info("âœ… æˆåŠŸåŠ è½½ç”Ÿäº§ç¯å¢ƒsystem prompts")
            logger.info(f"åŒ…å«çš„promptç±»å‹: {list(system_prompt.keys())}")
            
            return system_prompt
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½ç”Ÿäº§ç¯å¢ƒpromptså¤±è´¥: {e}")
            # å›é€€åˆ°ç®€åŒ–ç‰ˆæœ¬
            return {
                "GPT_STRUCTURED_PROMPT": """Analyze the contents from a git commit patch data and summarize the contents of the commit.
If the commit contains multiple files, please separate them into different items.
Please reply in the requested language."""
            }
    
    def test_problematic_commit(self, max_tokens=1000):
        """
        æµ‹è¯•å¯¼è‡´JSONæˆªæ–­çš„ç‰¹å®šcommit
        
        Args:
            max_tokens (int): GPTå“åº”çš„æœ€å¤§tokenæ•°ï¼Œé»˜è®¤1000ï¼ˆåŸå§‹å‡ºé”™å€¼ï¼‰
        """
        # å‡ºé—®é¢˜çš„commit URL
        commit_url = "https://api.github.com/repos/MicrosoftDocs/azure-ai-docs/commits/e126b9c4ee254b4ecaf72b12603bd34ea5bc1644"
        commit_time = datetime.datetime(2025, 9, 5, 14, 46, 11)  # ä»æ—¥å¿—ä¸­è·å–çš„æ—¶é—´
        
        logger.info(f"Testing commit: {commit_url}")
        logger.info(f"Testing with max_tokens: {max_tokens}")
        logger.info("=" * 80)
        
        try:
            # 1. è·å–commitçš„patchæ•°æ®
            logger.info("Step 1: è·å–commit patchæ•°æ®...")
            commit_patch_data = self.get_change_from_each_url(
                commit_time, 
                commit_url, 
                self.max_input_token, 
                self.headers
            )
            
            logger.info(f"Patchæ•°æ®é•¿åº¦: {len(commit_patch_data)} å­—ç¬¦")
            logger.info(f"Patchæ•°æ®é¢„è§ˆ:\n{commit_patch_data[:500]}...")
            logger.info("=" * 80)
            
            # 2. è°ƒç”¨GPTè¿›è¡Œç»“æ„åŒ–åˆ†æï¼ˆä½¿ç”¨åŸå§‹çš„max_tokenså€¼æ¥å¤ç°é—®é¢˜ï¼‰
            logger.info("Step 2: è°ƒç”¨GPTè¿›è¡Œç»“æ„åŒ–åˆ†æ...")
            result = self.test_gpt_structured_response(commit_patch_data, max_tokens)
            
            if result:
                logger.info("âœ… æµ‹è¯•æˆåŠŸå®Œæˆï¼")
                return result
            else:
                logger.error("âŒ æµ‹è¯•å¤±è´¥ - å¤ç°äº†JSONæˆªæ–­é—®é¢˜")
                return None
                
        except Exception as e:
            logger.exception(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
            return None
    
    def test_gpt_structured_response(self, commit_patch_data, max_tokens):
        """
        æµ‹è¯•GPTç»“æ„åŒ–å“åº”ï¼Œæ¨¡æ‹ŸåŸå§‹çš„è°ƒç”¨æ–¹å¼
        
        Args:
            commit_patch_data (str): commitçš„patchæ•°æ®
            max_tokens (int): GPTå“åº”çš„æœ€å¤§tokenæ•°
            
        Returns:
            dict or None: è§£ææˆåŠŸè¿”å›ç»“æ„åŒ–æ•°æ®ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # æ„å»ºç»“æ„åŒ–å“åº”æ ¼å¼ï¼ˆä¸åŸå§‹ä»£ç ç›¸åŒï¼‰
            response_format = {
                "type": "json_schema",
                "json_schema": {
                    "name": "commit_analysis",
                    "schema": {
                        "type": "object",
                        "properties": {
                            "summary": {"type": "string"},
                            "title": {"type": "string"},
                            "importance_score": {"type": "integer"},
                            "importance_score_reasoning": {"type": "string"}
                        },
                        "required": ["summary", "title", "importance_score", "importance_score_reasoning"],
                        "additionalProperties": False
                    }
                }
            }
            
            # æ„å»ºæ¶ˆæ¯ï¼ˆä¸åŸå§‹ä»£ç ç›¸åŒï¼‰
            system_message = f"{self.system_prompts['GPT_STRUCTURED_PROMPT']} Reply in {self.language}."
            messages = [
                {"role": "system", "content": system_message},
                {"role": "user", "content": f"Here are the commit patch data. #####{commit_patch_data} ##### Reply in {self.language}"},
            ]
            
            logger.debug(f"GPTè¯·æ±‚æ¶ˆæ¯: {messages}")
            
            # è°ƒç”¨GPTï¼ˆä½¿ç”¨æŒ‡å®šçš„max_tokensæ¥å¤ç°é—®é¢˜ï¼‰
            from gpt_reply import get_gpt_structured_response
            structured_response, prompt_tokens, completion_tokens, total_tokens = get_gpt_structured_response(
                messages, response_format, max_tokens=max_tokens
            )
            
            if structured_response is None:
                logger.error("âŒ GPTè¿”å›äº†None - å¤ç°äº†JSONæˆªæ–­é—®é¢˜ï¼")
                return None
            
            # å¦‚æœæˆåŠŸï¼Œè®°å½•ç»“æœ
            logger.info("âœ… GPTç»“æ„åŒ–å“åº”æˆåŠŸè§£æ:")
            logger.info(f"Summary: {structured_response.get('summary', 'N/A')}")
            logger.info(f"Title: {structured_response.get('title', 'N/A')}")
            logger.info(f"Importance Score: {structured_response.get('importance_score', 'N/A')}")
            logger.info(f"Tokenä½¿ç”¨: Prompt {prompt_tokens}, Completion {completion_tokens}, Total {total_tokens}")
            
            return structured_response
            
        except Exception as e:
            logger.exception(f"âŒ GPTç»“æ„åŒ–å“åº”å¤±è´¥: {e}")
            return None
    
    def run_comparison_test(self):
        """
        è¿è¡Œå¯¹æ¯”æµ‹è¯•ï¼šä½¿ç”¨ä¸åŒçš„max_tokenså€¼è¿›è¡Œæµ‹è¯•
        """
        logger.info("ğŸ§ª å¼€å§‹JSONæˆªæ–­é—®é¢˜å¯¹æ¯”æµ‹è¯•")
        logger.info("=" * 80)
        
        # æµ‹è¯•ä¸åŒçš„max_tokenså€¼
        test_cases = [
            ("åŸå§‹å€¼ï¼ˆä¼šå¯¼è‡´æˆªæ–­ï¼‰", 1000),
            ("ä¿®å¤å€¼1", 2000),
            ("ä¿®å¤å€¼2", 3000),
        ]
        
        results = {}
        
        for test_name, max_tokens in test_cases:
            logger.info(f"\nğŸ” æµ‹è¯•æ¡ˆä¾‹: {test_name} (max_tokens={max_tokens})")
            logger.info("-" * 60)
            
            result = self.test_problematic_commit(max_tokens)
            results[test_name] = {
                "max_tokens": max_tokens,
                "success": result is not None,
                "result": result
            }
            
            if result:
                logger.info(f"âœ… {test_name}: æˆåŠŸ")
            else:
                logger.info(f"âŒ {test_name}: å¤±è´¥ï¼ˆJSONæˆªæ–­ï¼‰")
        
        # æ€»ç»“æµ‹è¯•ç»“æœ
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
        for test_name, result_info in results.items():
            status = "âœ… æˆåŠŸ" if result_info["success"] else "âŒ å¤±è´¥"
            logger.info(f"{test_name} (max_tokens={result_info['max_tokens']}): {status}")
        
        return results


def main():
    """
    ä¸»å‡½æ•°ï¼šè¿è¡ŒJSONæˆªæ–­é—®é¢˜å¤ç°æµ‹è¯•
    """
    logger.info("ğŸš€ å¯åŠ¨JSONæˆªæ–­é—®é¢˜å¤ç°æµ‹è¯•")
    
    try:
        tester = JsonTruncationTester()
        
        # ç›´æ¥è¿è¡Œå¯¹æ¯”æµ‹è¯•ï¼ˆä¸éœ€è¦ç”¨æˆ·è¾“å…¥ï¼‰
        logger.info("ğŸ“ è¿è¡Œå¯¹æ¯”æµ‹è¯•æ¨¡å¼")
        results = tester.run_comparison_test()
        
        # æ˜¾ç¤ºç®€æ´çš„ç»“æœ
        print("\nğŸ“Š æµ‹è¯•ç»“æœ:")
        for test_name, info in results.items():
            status = "âœ…" if info["success"] else "âŒ"
            print(f"{status} {test_name}: max_tokens={info['max_tokens']}")
            
    except KeyboardInterrupt:
        logger.info("â¹ï¸  ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        logger.exception(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")


if __name__ == "__main__":
    main()
